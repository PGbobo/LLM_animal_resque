from flask import Flask, request, jsonify
from flask_cors import CORS
import base64
import time
import threading # â—€â—€ [ì¶”ê°€] ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ì„ ìœ„í•œ ìŠ¤ë ˆë”© ëª¨ë“ˆ

# -----------------------------------------------
# (ì¤‘ìš”) llm_animal.pyì˜ í•µì‹¬ ë¡œì§ì„ import
# (llm_animal.pyê°€ ê°™ì€ í´ë”ì— ìˆë‹¤ê³  ê°€ì •)
import llm_animal
# -----------------------------------------------

import faiss
import json
import numpy as np
import pymysql

# 1. Flask ì•± ìƒì„± ë° CORS ì„¤ì •
app = Flask(__name__)
CORS(app) # â—€â—€ ëª¨ë“  ë„ë©”ì¸ì—ì„œì˜ ìš”ì²­ì„ í—ˆìš© (React í…ŒìŠ¤íŠ¸ìš©)

# MySQL DB ì„¤ì • (animal_crawler.pyì™€ ë™ì¼í•˜ê²Œ)
DB_CONFIG = {
    "host": "project-db-campus.smhrd.com",
    "port": 3307,
    "user": "campus_24IS_CLOUD3_p3_1",
    "password": "smhrd1",
    "database": "campus_24IS_CLOUD3_p3_1",
    "charset": "utf8mb4",
    "cursorclass": pymysql.cursors.DictCursor
}
# 2. (í•„ìˆ˜) í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì— í•„ìš”í•œ DB/ì¸ë±ìŠ¤ ì „ì—­ ë¡œë“œ
g_adopt_index = None
g_adopt_db_full = None
g_missing_index = None
g_missing_db_full = None

def load_ai_models(): # â—€â—€ í•¨ìˆ˜ë¡œ ë¬¶ê¸°
    global g_adopt_index, g_adopt_db_full, g_missing_index, g_missing_db_full
    print("--- AI ëª¨ë¸ ë¡œë“œ ì‹œì‘ ---")
    try:
        # --- DB 1: ì…ì–‘ë™ë¬¼ (Adoption) DB ë¡œë“œ ---
        print(f"'{llm_animal.INDEX_FILE}' (ì…ì–‘DB) ë¡œë“œ ì¤‘...")
        g_adopt_index = faiss.read_index(llm_animal.INDEX_FILE)

        print(f"'{llm_animal.ID_MAP_FILE}' (ì…ì–‘DB ë§µ) ë¡œë“œ ì¤‘...")
        with open(llm_animal.ID_MAP_FILE, "r", encoding="utf-8") as f:
            # (ë³€ìˆ˜ëª… ì£¼ì˜: g_adopt_id_mapì€ ì „ì—­ë³€ìˆ˜ ì„ ì–¸ ì•ˆ í•´ë„ ë¨, ë‚´ë¶€ ì‚¬ìš©)
            json.load(f)

        print(f"'{llm_animal.DB_FILE}' (ì…ì–‘DB ì›ë³¸) ë¡œë“œ ì¤‘...")
        with open(llm_animal.DB_FILE,"r",encoding="utf-8") as f:
            g_adopt_db_full = json.load(f)
        print(f"âœ… ì…ì–‘DB ë¡œë“œ ì™„ë£Œ (ì´ {len(g_adopt_db_full)}ê°œ í•­ëª©)")

        # --- DB 2: ì‹¤ì¢…ë™ë¬¼ (Missing) DB ë¡œë“œ ---
        MISSING_INDEX_FILE = "missing_vectors.index"
        MISSING_MAP_FILE = "missing_map.json"
        MISSING_DB_FILE = "missing_pets.json"

        print(f"'{MISSING_INDEX_FILE}' (ì‹¤ì¢…DB) ë¡œë“œ ì¤‘...")
        g_missing_index = faiss.read_index(MISSING_INDEX_FILE)

        print(f"'{MISSING_MAP_FILE}' (ì‹¤ì¢…DB ë§µ) ë¡œë“œ ì¤‘...")
        with open(MISSING_MAP_FILE, "r", encoding="utf-8") as f:
            json.load(f)

        print(f"'{MISSING_DB_FILE}' (ì‹¤ì¢…DB ì›ë³¸) ë¡œë“œ ì¤‘...")
        with open(MISSING_DB_FILE,"r",encoding="utf-8") as f:
            g_missing_db_full = json.load(f)
        print(f"âœ… ì‹¤ì¢…DB ë¡œë“œ ì™„ë£Œ (ì´ {len(g_missing_db_full)}ê°œ í•­ëª©)")

    except Exception as e:
        print(f"âŒ [ì¹˜ëª…ì  ì˜¤ë¥˜] DB íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

# â—€â—€ ì„œë²„ ì‹œì‘ ì‹œ ìµœì´ˆ 1íšŒ ì‹¤í–‰
load_ai_models()
print("\nâœ… ëª¨ë“  DB ë¡œë“œ ì™„ë£Œ. API ì„œë²„ ëŒ€ê¸° ì¤‘...")
# -----------------------------------------------------------------

# "ì‹ í˜¸ ì£¼ê¸°" í—¬í¼ í•¨ìˆ˜
def create_notification_signal(user_num, message):
    """
    NOTIFICATIONS í…Œì´ë¸”ì— 'pending' ìƒíƒœë¡œ ìƒˆ ì•Œë¦¼ì„ INSERTí•©ë‹ˆë‹¤.
    """
    conn = None
    curs = None

    try:
        conn = pymysql.connect(**DB_CONFIG)
        curs = conn.cursor()

        sql = """
        INSERT INTO NOTIFICATIONS (user_num, message, status)
        VALUES (%s, %s, 'pending')
        """
        curs.execute(sql, (user_num, message))
        conn.commit()
        print(f"  [ğŸ”” ì•Œë¦¼ ì‹ í˜¸ ìƒì„±] User {user_num}ì—ê²Œ '{message[:20]}...' ì „ì†¡ ì˜ˆì•½")

    except Exception as e:
        print(f"  [âŒ ì•Œë¦¼ ì‹ í˜¸ ì‹¤íŒ¨] User {user_num} DB INSERT ì‹¤íŒ¨: {e}")
        if conn: conn.rollback()
    finally:
        if curs: curs.close()
        if conn: conn.close()

def get_user_details_from_db(user_num):
    """
    USERS í…Œì´ë¸”ì—ì„œ user_idë¡œ ì—°ë½ì²˜ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    conn = None
    curs = None
    try:
        conn = pymysql.connect(**DB_CONFIG)
        curs = conn.cursor()

        # (ì£¼ì˜: USERS í…Œì´ë¸”ê³¼ user_id ì»¬ëŸ¼ëª…ì´ ì‹¤ì œì™€ ì¼ì¹˜í•´ì•¼ í•¨)
        curs.execute("SELECT phone, telegram_chat_id FROM USERS WHERE USER_NUM = %s", (user_num,))
        user_details = curs.fetchone()

        if user_details:
            return user_details
        else:
            return None

    except Exception as e:
        print(f"  [âŒ DB ì¡°íšŒ ì‹¤íŒ¨] USERS í…Œì´ë¸” ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None
    finally:
        if curs: curs.close()
        if conn: conn.close()

# í—¬ìŠ¤ ì²´í¬(Health Check) ì—”ë“œí¬ì¸íŠ¸
@app.route('/', methods=['GET'])
def health_check():
    print("[ìš”ì²­ ìˆ˜ì‹ ] / (Health Check)")
    # ì´ ì£¼ì†Œë¡œ ì ‘ì†í•˜ë©´ "ok" ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    return jsonify({"status": "ok", "message": "API ì„œë²„ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤."})

# 3. (í•µì‹¬) ì´ë¯¸ì§€ ê²€ìƒ‰ API ì—”ë“œí¬ì¸íŠ¸ ìƒì„±
@app.route('/api/search', methods=['POST'])
def handle_search():
    print("\n[ìš”ì²­ ìˆ˜ì‹ ] /api/search")

    # 1. Reactê°€ ë³´ë‚¸ ì´ë¯¸ì§€ ë°ì´í„°(Base64) ë°›ê¸°
    data = request.json
    if 'image_base64' not in data:
        return jsonify({"error": "ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

    image_data_b64 = data['image_base64']
    (start_time_total) = time.time()

    try:
        # 2. ì¿¼ë¦¬ ì´ë¯¸ì§€ ë¶„ì„ (llm_animal.pyì˜ í•¨ìˆ˜ ì¬ì‚¬ìš©)
        # (analyze_image_bytes í•¨ìˆ˜ëŠ” Base64ë¥¼ ì¸ìë¡œ ë°›ìœ¼ë¯€ë¡œ ì™„ë²½í•¨)
        query_obj = llm_animal.analyze_image_bytes(image_data_b64, "api_query.jpg")
        if not query_obj:
            return jsonify({"error": "LLM ë¶„ì„ ì‹¤íŒ¨"}), 500

        query_attr_emb = llm_animal.get_embeddings_for_attributes(query_obj)
        if not (query_attr_emb and "__merged__" in query_attr_emb):
            return jsonify({"error": "ì„ë² ë”© ìƒì„± ì‹¤íŒ¨"}), 500

        print(f"âœ… ì¿¼ë¦¬ ë²¡í„° ìƒì„± ì™„ë£Œ")

        # 3. FAISS + í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰ (llm_animal.pyì˜ ë¡œì§ ì¬ì‚¬ìš©)
        query_merged_vector = query_attr_emb["__merged__"]
        query_vector_np = np.array([query_merged_vector]).astype('float32')
        faiss.normalize_L2(query_vector_np)

        D_faiss, I_faiss = g_adopt_index.search(query_vector_np, llm_animal.K_CANDIDATES)
        candidate_indices = I_faiss[0]

        query_species = query_obj.get("dog_or_cat_or_other")
        final_results_data = [] # â—€ JSONìœ¼ë¡œ ë°˜í™˜í•  ë¦¬ìŠ¤íŠ¸

        for idx in candidate_indices:
            item = g_adopt_db_full[idx]
            if item.get("attributes", {}).get("dog_or_cat_or_other") == query_species:
                score = llm_animal.compare_query_to_item(query_attr_emb, item)
                final_results_data.append({
                    "filename": item["filename"],
                    "score": score
                })

        final_results_data.sort(key=lambda x: x["score"], reverse=True)

        print(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ (ì´ {time.time() - start_time_total:.2f}ì´ˆ)")

        # 4. Reactì—ê²Œ Top 10 ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì‘ë‹µ
        return jsonify({
            "message": "ê²€ìƒ‰ ì„±ê³µ",
            "results": final_results_data[:llm_animal.K_FINAL] #
        })

    except Exception as e:
        print(f"âŒ /api/search ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜: {e}")
        return jsonify({"error": str(e)}), 500

# 4. ìì—°ì–´ ê¸°ë°˜ ì…ì–‘ ì¶”ì²œ API ì—”ë“œí¬ì¸íŠ¸
@app.route('/api/adapt', methods=['POST'])
def handle_adapt_recommendation():
    print("\n[ìš”ì²­ ìˆ˜ì‹ ] /api/adapt") # â—€ ì£¼ì†Œ ë³€ê²½

    # 1. Reactê°€ ë³´ë‚¸ 'í…ìŠ¤íŠ¸' ë°ì´í„° ë°›ê¸°
    data = request.json
    if 'query_text' not in data: # â—€ 'image_base64' ëŒ€ì‹  'query_text'
        return jsonify({"error": "í…ìŠ¤íŠ¸ ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

    query_text = data['query_text'] # â—€ 'image_base64' ëŒ€ì‹  'query_text'
    (start_time_total) = time.time()

    try:
        # 2. í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ -> JSONìœ¼ë¡œ ë²ˆì—­
        query_obj = llm_animal.analyze_text_with_llm(query_text)
        if not query_obj:
            return jsonify({"error": "LLM í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨"}), 500

        # 3. ë²ˆì—­ëœ JSONì„ -> ë²¡í„°ë¡œ ë³€í™˜
        query_attr_emb = llm_animal.get_embeddings_for_attributes(query_obj)
        if not (query_attr_emb and "__merged__" in query_attr_emb):
            return jsonify({"error": "ì„ë² ë”© ìƒì„± ì‹¤íŒ¨"}), 500

        print(f"âœ… ì¿¼ë¦¬ ë²¡í„° ìƒì„± ì™„ë£Œ")

        # 4. FAISS + í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
        query_merged_vector = query_attr_emb["__merged__"]
        query_vector_np = np.array([query_merged_vector]).astype('float32')
        faiss.normalize_L2(query_vector_np)

        D_faiss, I_faiss = g_adopt_index.search(query_vector_np, llm_animal.K_CANDIDATES)
        candidate_indices = I_faiss[0]

        # 5. 'ì¢…' í•„í„°ë§ ë° ê°€ì¤‘ì¹˜ ì¬ì •ë ¬
        query_species = query_obj.get("dog_or_cat_or_other")
        final_results_data = []

        for idx in candidate_indices:
            item = g_adopt_db_full[idx]

            # (ì¤‘ìš”) LLMì´ 'ê°œ'ë¼ê³  ë²ˆì—­í–ˆìœ¼ë©´, ê³ ì–‘ì´ëŠ” ì—¬ê¸°ì„œ ìë™ í•„í„°ë§ë¨
            if item.get("attributes", {}).get("dog_or_cat_or_other") == query_species:

                # (ì¤‘ìš”) `weights`ê°€ ì—¬ê¸°ì„œ 100% ë™ì¼í•˜ê²Œ ì ìš©ë¨
                score = llm_animal.compare_query_to_item(query_attr_emb, item)
                final_results_data.append({
                    "filename": item["filename"],
                    "score": score
                })

        final_results_data.sort(key=lambda x: x["score"], reverse=True)

        print(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ (ì´ {time.time() - start_time_total:.2f}ì´ˆ)")

        # 6. (100% ë™ì¼) â—€â—€ Reactì—ê²Œ Top 10 ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì‘ë‹µ
        return jsonify({
            "message": "ê²€ìƒ‰ ì„±ê³µ",
            "results": final_results_data[:llm_animal.K_FINAL]
        })

    except Exception as e:
        print(f"âŒ /api/adapt ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜: {e}")
        return jsonify({"error": str(e)}), 500

# ì‹¤ì¢…ë™ë¬¼ ì œë³´ API (ì‚¬ì§„/í…ìŠ¤íŠ¸ ê²¸ìš©)
# -----------------------------------------------------------------
@app.route('/api/report_sighting', methods=['POST'])
def handle_sighting_report():
    print("\n[ìš”ì²­ ìˆ˜ì‹ ] /api/report_sighting (ì‹¤ì¢…DB ê²€ìƒ‰)")
    data = request.json

    # â—€ ì‚¬ì§„ ë˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë°›ìŒ
    image_data_b64 = data.get('image_base64') # (Optional)
    query_text = data.get('query_text')       # (Optional)
    (start_time_total) = time.time()

    try:
        query_obj = None

        # 1. ì¿¼ë¦¬ ë¶„ì„ (ì‚¬ì§„/í…ìŠ¤íŠ¸ ë¶„ê¸° ì²˜ë¦¬)
        if image_data_b64:
            print("[ì œë³´ ìœ í˜•] ì‚¬ì§„")
            query_obj = llm_animal.analyze_image_bytes(image_data_b64, "api_query_sighting.jpg")
        elif query_text:
            print("[ì œë³´ ìœ í˜•] í…ìŠ¤íŠ¸")
            query_obj = llm_animal.analyze_text_with_llm(query_text)
        else:
            return jsonify({"error": "ì´ë¯¸ì§€ ë˜ëŠ” í…ìŠ¤íŠ¸ ì¿¼ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        if not query_obj: return jsonify({"error": "LLM ì¿¼ë¦¬ ë¶„ì„ ì‹¤íŒ¨"}), 500

        # 2. ì„ë² ë”© (ê³µí†µ ë¡œì§ ì¬ì‚¬ìš©)
        query_attr_emb = llm_animal.get_embeddings_for_attributes(query_obj)
        if not (query_attr_emb and "__merged__" in query_attr_emb):
            return jsonify({"error": "ì„ë² ë”© ìƒì„± ì‹¤íŒ¨"}), 500

        print(f"âœ… ì œë³´ ì¿¼ë¦¬ ë²¡í„° ìƒì„± ì™„ë£Œ")

        # 3. â—€â—€ [í•µì‹¬] í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (g_missing_... ë³€ìˆ˜ ì‚¬ìš©)
        query_merged_vector = query_attr_emb["__merged__"]
        query_vector_np = np.array([query_merged_vector]).astype('float32')
        faiss.normalize_L2(query_vector_np)

        # (ì¤‘ìš”) â—€ 'ì‹¤ì¢…ë™ë¬¼' ì¸ë±ìŠ¤ë¥¼ ê²€ìƒ‰
        D_faiss, I_faiss = g_missing_index.search(query_vector_np, llm_animal.K_CANDIDATES)
        candidate_indices = I_faiss[0]

        query_species = query_obj.get("dog_or_cat_or_other")
        final_results_data = []

        alerted_user_ids = set() # â—€ ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€ìš© Set

        # DB ì—°ê²°
        conn = pymysql.connect(**DB_CONFIG)
        curs = conn.cursor()

        for idx in candidate_indices:
            # (ì¤‘ìš”) â—€ 'ì‹¤ì¢…ë™ë¬¼' DBì—ì„œ ì•„ì´í…œ ì¡°íšŒ
            item = g_missing_db_full[idx]
            if item.get("attributes", {}).get("dog_or_cat_or_other") == query_species:
                score = llm_animal.compare_query_to_item(query_attr_emb, item)

                # --- [ì‹ ê·œ 4] â—€ "ì‹ í˜¸ ì£¼ê¸°" ë¡œì§ ---
                if score >= 0.80: # â—€ 80% ì´ìƒ ë§¤ì¹­!

                    # (ê°€ì •) â—€ ì‹¤ì¢…ë™ë¬¼ DBì˜ attributesì— user_num (PK)ì´ ì €ì¥ë˜ì–´ ìˆì–´ì•¼ í•¨
                    owner_user_num = item.get("attributes", {}).get("user_num")

                    if owner_user_num and owner_user_num not in alerted_user_ids:
                        print(f"  [ğŸ”” 80% ë§¤ì¹­ ë°œê²¬!] ì‹¤ì¢…ë™ë¬¼: {item.get('filename')}, ì£¼ì¸ ID: {owner_user_num}")

                        # â—€â—€ [ìˆ˜ì •] íŒŒì¼ëª…ì—ì„œ ì´ë¦„ ì¶”ì¶œ ë¡œì§
                        full_path = item.get('filename', '') # ì˜ˆ: abandon/missing/5_ë½€ì‚_1234.jpg
                        pet_name = "ë°˜ë ¤ë™ë¬¼" # ê¸°ë³¸ê°’
                        try:
                            # 1. ê²½ë¡œ ë–¼ê³  íŒŒì¼ëª…ë§Œ (5_ë½€ì‚_1234.jpg)
                            file_only = full_path.split('/')[-1]
                            # 2. ì–¸ë”ë°”(_)ë¡œ ìª¼ê°œì„œ ë‘ ë²ˆì§¸ ë©ì–´ë¦¬(ì´ë¦„) ê°€ì ¸ì˜¤ê¸°
                            pet_name = file_only.split('_')[1]
                        except:
                            pass # ì´ë¦„ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©

                        # 1. ì•Œë¦¼ ë©”ì‹œì§€ ìƒì„±
                        message = f"[ì´ì–´ì£¼ê°œ] íšŒì›ë‹˜ì˜ ì‹¤ì¢…ë™ë¬¼ '{pet_name}'ê³¼(ì™€) {score*100:.0f}% ìœ ì‚¬í•œ ë™ë¬¼ì´ ì œë³´ë˜ì—ˆìŠµë‹ˆë‹¤! \n\nâ–¶í™ˆí˜ì´ì§€ í™•ì¸í•˜ê¸°\nhttp://connectdog.kro.kr/"

                        # 2. (ìˆ˜ì •) â—€ ì´ˆê°„ë‹¨ "ì‹ í˜¸" INSERT (ì—°ë½ì²˜ ì¡°íšŒ ì•ˆ í•¨)
                        create_notification_signal(owner_user_num, message)

                        alerted_user_ids.add(owner_user_num)

                # DBì—ì„œ 'ì´ë¦„'ê³¼ 'ì¥ì†Œ' ì¡°íšŒ
                # (S3 í‚¤ëŠ” "abandon/missing/..." í˜•ì‹ì´ë¯€ë¡œ LIKE ê²€ìƒ‰)
                s3_key = item["filename"]
                pet_name_db = "ì´ë¦„ ë¯¸ìƒ"
                lost_loc_db = "ìœ„ì¹˜ ì •ë³´ ì—†ìŒ"

                try:
                    # PET_IMAGE_URLì— s3_keyê°€ í¬í•¨ëœ ë ˆì½”ë“œë¥¼ ì°¾ìŒ
                    sql = "SELECT PET_NAME, LOST_LOCATION FROM MISSING WHERE PET_IMAGE_URL LIKE %s"
                    curs.execute(sql, (f"%{s3_key}",))
                    row = curs.fetchone()
                    if row:
                        pet_name_db = row['PET_NAME']
                        lost_loc_db = row['LOST_LOCATION']
                except Exception as e:
                    print(f"  [DB ì¡°íšŒ ì—ëŸ¬] {s3_key}: {e}")

                final_results_data.append({
                    "filename": item["filename"],
                    "score": score,
                    "petName": pet_name_db,   # â—€ DBì—ì„œ ê°€ì ¸ì˜¨ ì´ë¦„
                    "location": lost_loc_db   # â—€ DBì—ì„œ ê°€ì ¸ì˜¨ ìœ„ì¹˜
                })

        final_results_data.sort(key=lambda x: x["score"], reverse=True)

        print(f"âœ… /api/report_sighting ê²€ìƒ‰ ì™„ë£Œ (ì´ {time.time() - start_time_total:.2f}ì´ˆ)")
        return jsonify({"message": "ê²€ìƒ‰ ì„±ê³µ", "results": final_results_data[:llm_animal.K_FINAL]})

    except Exception as e:
        print(f"âŒ /api/report_sighting ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜: {e}")
        return jsonify({"error": str(e)}), 500

    finally:
        # â—€â—€ [í•µì‹¬] ì—ëŸ¬ê°€ ë‚˜ë“  ì„±ê³µí•˜ë“  DB ì—°ê²°ì„ ë°˜ë“œì‹œ ë‹«ìŒ
        if curs: curs.close()
        if conn: conn.close()

# â—€â—€ [í•µì‹¬ ìˆ˜ì •] ìƒˆë¡œê³ ì¹¨ API (ë¹„ë™ê¸° ì²˜ë¦¬)
@app.route('/api/refresh_index', methods=['POST', 'GET'])
def refresh_index():
    print("\n[ìš”ì²­ ìˆ˜ì‹ ] /api/refresh_index (Hot Reload - Background)")

    # 1. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰í•  ë‚´ë¶€ í•¨ìˆ˜ ì •ì˜
    def background_task():
        try:
            print("â³ [Background] ì¸ë±ìŠ¤ ê°±ì‹  ë° AI ëª¨ë¸ ë¦¬ë¡œë“œ ì‹œì‘...")
            
            # (ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…) S3 ìŠ¤ìº” -> JSON/Index ì¬ìƒì„±
            success = llm_animal.refresh_missing_data_from_db()
            
            if success:
                # (ë©”ëª¨ë¦¬ ë¡œë“œ) ì „ì—­ë³€ìˆ˜ êµì²´
                load_ai_models()
                print("âœ… [Background] ì¸ë±ìŠ¤ ìµœì‹ í™” ì™„ë£Œ! ì´ì œ ê²€ìƒ‰ì— ë°˜ì˜ë©ë‹ˆë‹¤.")
            else:
                print("âŒ [Background] ì¸ë±ìŠ¤ ê°±ì‹  ì‹¤íŒ¨")
        except Exception as e:
            print(f"âŒ [Background] ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì¤‘ ì—ëŸ¬: {e}")

    # 2. ìŠ¤ë ˆë“œ ìƒì„± ë° ì‹œì‘ (ì¦‰ì‹œ ë¦¬í„´ë¨)
    thread = threading.Thread(target=background_task)
    thread.daemon = True # ë©”ì¸ í”„ë¡œì„¸ìŠ¤ê°€ ì£½ìœ¼ë©´ ê°™ì´ ì£½ë„ë¡ ì„¤ì •
    thread.start()

    # 3. ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ë°”ë¡œ ì„±ê³µ ì‘ë‹µ ë°˜í™˜ (0.1ì´ˆ ì†Œìš”)
    return jsonify({"message": "ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì¸ë±ìŠ¤ ê°±ì‹ ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. (ì ì‹œ í›„ ë°˜ì˜ë¨)"})

# 7. API ì„œë²„ ì‹¤í–‰
if __name__ == '__main__':
    # ë””ë²„ê·¸ ëª¨ë“œëŠ” ëˆ(False) ìƒíƒœë¡œ ë°°í¬í•©ë‹ˆë‹¤.
    app.run(host='0.0.0.0', port=5000, debug=False)
